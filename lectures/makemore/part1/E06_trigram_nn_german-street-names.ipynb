{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_4hGhfqr77"
      },
      "source": [
        "E06: meta-exercise! Think of a fun/interesting exercise and complete it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cXqCEa9qr78"
      },
      "source": [
        "My idea is to use the model on a different data set, and see how it performs. I will use German street names, from the [OpenAdresses dataset of Germany](https://www.kaggle.com/datasets/openaddresses/openaddresses-europe?resource=download&select=germany.csv)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is advised to run this notebook on a GPU, as it will take a long time to train on a CPU. I ran it on a Google Colab GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "xS99zWIxlYnF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "Ah7BOf_Eqr7-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHQXU5U6u03X",
        "outputId": "dc9fc185-9351-4523-edcf-341aebc2524e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "smXrGT8fkBXb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Read in the dataset\n",
        "# Adjust the path to the file on your computer or in the cloud\n",
        "streetnames = open('./street-names.txt', 'r', encoding='utf-8').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJljXmQdqr7_",
        "outputId": "cf25be66-1ef4-4780-f24d-1959ebf372b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['am hohen rand',\n",
              " 'lehrer-geßner-straße',\n",
              " 'wittekindallee',\n",
              " 'am darloh',\n",
              " 'taxusweg',\n",
              " 'hinterm friedhof',\n",
              " 'kleine wende',\n",
              " 'an der liff',\n",
              " 'posthorn',\n",
              " 'landsberger allee']"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "streetnames[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "yRzVx_hBqr7_"
      },
      "outputs": [],
      "source": [
        "# Create training, dev, and test sets\n",
        "train_index = floor(len(streetnames) * 0.90)\n",
        "dev_index = floor(len(streetnames) * 0.95)\n",
        "\n",
        "train = streetnames[:train_index]\n",
        "dev = streetnames[train_index:dev_index]\n",
        "test = streetnames[dev_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "GJq5MXh02Az4"
      },
      "outputs": [],
      "source": [
        "special_token = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "MSYXOJdDl_WC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join([special_token] + streetnames))))\n",
        "\n",
        "# Create look up tables for the alphabet and other characters.\n",
        "  # stoi = string to index\n",
        "  # itos = index to string\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for s, i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho2wAPG21H_o",
        "outputId": "a0a39c17-e798-4356-cf52-e7dbe8a72fc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([' ', '&', \"'\", '-', '.', ':', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ß', 'ä', 'ö', 'ü'])"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "itos.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yn3roeTqr8A",
        "outputId": "1d6bba4c-bb96-468a-b62d-9742bd354d29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars_size = len(chars)\n",
        "chars_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvmdz3M6luLH",
        "outputId": "1b52a0ed-c29e-45c7-f5e9-536cbb1f28bb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of training examples:  1965683\n"
          ]
        }
      ],
      "source": [
        "xs_train,  ys_train = [], []\n",
        "\n",
        "# Create the training data\n",
        "# input xs: (ch1, ch2) \n",
        "# prediction ys: ch3\n",
        "for streetname in train:\n",
        "\n",
        "  # prepend two special characters and append one special characters to each streetname\n",
        "  chs = [special_token] * 2 + list(streetname) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_train.append((ix1, ix2))\n",
        "    ys_train.append(ix3)\n",
        "\n",
        "num = len(xs_train)\n",
        "print('number of training examples: ', num)\n",
        "xs_train = torch.tensor(xs_train, device=device)\n",
        "ys_train = torch.tensor(ys_train, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH8z6Bs0qr8B",
        "outputId": "570c0314-8eb2-46c5-ffa1-4daa4cf77a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of development examples:  40084\n"
          ]
        }
      ],
      "source": [
        "# Create the dev data\n",
        "xs_dev,  ys_dev = [], []\n",
        "for word in dev:\n",
        "  chs = [special_token] * 2 + list(word) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_dev.append((ix1, ix2))\n",
        "    ys_dev.append(ix3)\n",
        "\n",
        "xs_dev = torch.tensor(xs_dev, device=device)\n",
        "ys_dev = torch.tensor(ys_dev, device=device)\n",
        "print('number of development examples: ', xs_dev.nelement())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1y0NbDZqr8C",
        "outputId": "e6d70f7b-6dd9-4719-d331-a45852ad766b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of testing examples:  39736\n"
          ]
        }
      ],
      "source": [
        "# Create the test data\n",
        "xs_test,  ys_test = [], []\n",
        "for word in test:\n",
        "  chs = [special_token] * 2 + list(word) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_test.append((ix1, ix2))\n",
        "    ys_test.append(ix3)\n",
        "\n",
        "xs_test = torch.tensor(xs_test, device=device)\n",
        "ys_test = torch.tensor(ys_test, device=device)\n",
        "print('number of testing examples: ', xs_test.nelement())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "7ZQ_3pnsqr8C"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator(device=device).manual_seed(2147483647)\n",
        "W = torch.randn((chars_size*2, chars_size), generator=g, device=device, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw78JHSfqr8D",
        "outputId": "c6dfddc5-0d00-4e15-aa6e-8e1c8798813b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss at step 0: 4.512\n",
            "loss at step 10: 2.472\n",
            "loss at step 20: 2.283\n",
            "loss at step 30: 2.208\n",
            "loss at step 40: 2.169\n",
            "loss at step 50: 2.145\n",
            "loss at step 60: 2.128\n",
            "loss at step 70: 2.117\n",
            "loss at step 80: 2.109\n",
            "loss at step 90: 2.102\n",
            "final training loss: 2.097, with smoothing strength 0.01\n"
          ]
        }
      ],
      "source": [
        "# gradient descent\n",
        "iterations = 500\n",
        "learning_rate = 200\n",
        "smoothing_strenth = 0.01\n",
        "\n",
        "for k in range(iterations):\n",
        "\n",
        "  # forward pass\n",
        "  xenc= F.one_hot(xs_train, num_classes=chars_size).float()\n",
        "  xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "  logits = xenc_flat @ W # predict log-counts\n",
        "  loss = F.cross_entropy(logits, ys_train) + smoothing_strenth * (W**2).mean() # compute loss\n",
        "  # print loss every 10% of iterations\n",
        "  if k % floor(iterations/10) == 0:\n",
        "    print(f'loss at step {k}: {loss.item():.3f}')\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # flush the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # update step\n",
        "  cooldown = 1.0 / (1 + 0.001 * k)\n",
        "  W.data += -learning_rate * cooldown * W.grad\n",
        "print(f'final training loss: {loss.item():.3f}, with smoothing strength {smoothing_strenth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sJQXZYBqr8D",
        "outputId": "3f99f8d7-4f1a-4469-87b9-8a92d59a8e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss on dev set: 2.089, with smoothing strength 0.01\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the dev set\n",
        "xenc= F.one_hot(xs_dev, num_classes=chars_size).float()\n",
        "xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "logits = xenc_flat @ W # predict log-counts\n",
        "# softmax\n",
        "counts = logits.exp() # counts\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# loss function (cross-entropy) + regularization (L2)\n",
        "loss = F.cross_entropy(logits, ys_dev)\n",
        "print(f'loss on dev set: {loss.item():.3f}, with smoothing strength {smoothing_strenth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqlMBsbXqr8D",
        "outputId": "42c67a35-ec96-4d60-df98-99ebaf56c298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss on test set: 2.109\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "xenc= F.one_hot(xs_test, num_classes=chars_size).float()\n",
        "xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "logits = xenc_flat @ W # predict log-counts\n",
        "# softmax\n",
        "counts = logits.exp() # counts\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# loss function (cross-entropy) + regularization (L2)\n",
        "loss = F.cross_entropy(logits, ys_test) + smoothing_strenth * (W**2).mean() # compute loss\n",
        "print(f'loss on test set: {loss.item():.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0mkbei4qr8E",
        "outputId": "f1d953d2-3e98-4795-87ef-282d1b1bb66d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ga'ntistraße.\n",
            "qmelb.\n",
            "hanwkh.\n",
            "ber kachrebskend.\n",
            "aner straße.\n",
            "bah-z-weg.\n",
            "aufsweg.\n",
            "dimp.\n",
            "rindruck.\n",
            "haldimpek.\n",
            "em-nel.\n",
            "sendenüstraßekfedhep.\n",
            "eueg.\n",
            "imgswim ben-ung-stjö dek mperhäeweg.\n",
            "zur sanam wickldergen de.\n",
            "ausweg.\n",
            "mmnben ste.\n",
            "her-aße.\n",
            "nnade.\n",
            "witraße.\n",
            "haundeit.\n",
            "litran.\n",
            "äme-d.\n",
            "weg.\n",
            "kornstr der wegern.\n",
            "traße.\n",
            "bustraßqscheytraße.\n",
            "bengeneg.\n",
            "ploweg.\n",
            "aun-ld.\n",
            "strasteraße.\n",
            "mm.\n",
            "raße.\n",
            "lashöuqgastritzsthng.\n",
            "rintrtraße.\n",
            "der brstristraße.\n",
            "gr-stjaltraße.\n",
            "karoße.\n",
            "aidek.\n",
            "ooskühle.\n",
            "gaughof.\n",
            "p:ang.\n",
            "alem-hofeiwel.\n",
            "vmperlt.\n",
            "mablen.\n",
            "brobelteltselskrit.\n",
            "erger straße.\n",
            "düttel.\n",
            "ll' st.\n",
            "kimeler derteöllitz-wer ok.\n",
            "vmersiehruen.\n",
            "kor-traße.\n",
            "er we-mbickurnschatzeiderg.\n",
            "margße.\n",
            "pastraße.\n",
            "bucherstraße.\n",
            "ptraße.\n",
            "kllannuck.\n",
            "almeödskrhof-wied.\n",
            "anshaldedengen.\n",
            "erg.\n",
            "alttam -raße.\n",
            "allustenstrochgsxüen-saße.\n",
            "dor hof dorerm weg.\n",
            "me.\n",
            "bokiegh.\n",
            "orheim duer bergender dorsthornchaweg.\n",
            "eipfä.\n",
            "för bick.\n",
            "zlickller steeberzumratze&.\n",
            "tzlstramz.\n",
            "der strackserweg straße.\n",
            "raße.\n",
            "ben dg.\n",
            "dostz.\n",
            "scherg.\n",
            "ome.\n",
            "cherenndimpeieb&plamplaße.\n",
            "matzälee.\n",
            "puer sisstobraße.\n",
            "bie müöl.\n",
            "am straße.\n",
            "ot.\n",
            "aufrdosterssügen.\n",
            "fenborfelste.\n",
            "scheam hofeckitin-schn:scd.\n",
            "nippten.\n",
            "am welkelstraße.\n",
            "xlawße.\n",
            "drkan straße.\n",
            "ho.\n",
            "bote.\n",
            "kordkaästraße.\n",
            "dumeiedsmergumatfallischwegl&neßk.\n",
            "taleum or aldwehuschswiächern-hoffustalderüildengsseneg.\n",
            "ausße.\n",
            "ammpachße.\n",
            "dosweiderlholau -wig.\n",
            "karin.\n",
            "lohmarestraße.\n"
          ]
        }
      ],
      "source": [
        "g = torch.Generator(device=device).manual_seed(2147483647)\n",
        "# sample street names\n",
        "name_count = 100\n",
        "sampled_street_names = []\n",
        "for i in range(name_count):\n",
        "\n",
        "  out = []\n",
        "  ix1 = stoi[special_token]\n",
        "  ix2 = stoi[special_token]\n",
        "\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2], device=device), num_classes=chars_size).float()\n",
        "    xenc_flat = xenc.flatten()\n",
        "    logits = xenc_flat @ W # predict log-counts\n",
        "    # softmax\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(0, keepdims=True) # probabilities for next character\n",
        "    \n",
        "    # move index to next character\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == stoi[special_token]:\n",
        "      # stop if we reach the end of the word\n",
        "      # 0 is the index of the special character '.'\n",
        "      break\n",
        "\n",
        "  sampled_street_names.append(''.join(out))\n",
        "for streetname in sampled_street_names:\n",
        "  print(streetname)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
