{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_4hGhfqr77"
      },
      "source": [
        "E06: meta-exercise! Think of a fun/interesting exercise and complete it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cXqCEa9qr78"
      },
      "source": [
        "My idea is to use the model on a different data set, and see how it performs. I will use German street names, from the [OpenAdresses dataset of Germany](https://www.kaggle.com/datasets/openaddresses/openaddresses-europe?resource=download&select=germany.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "xS99zWIxlYnF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "Ah7BOf_Eqr7-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHQXU5U6u03X",
        "outputId": "e1279931-28a9-47c7-f6f0-1dbf84d7cd12"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "smXrGT8fkBXb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Read in the dataset\n",
        "streetnames = open('./sample_data/street-names.txt', 'r', encoding='utf-8').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJljXmQdqr7_",
        "outputId": "f4440b4f-68a6-491e-9f94-e5082c2f84db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['am hohen rand',\n",
              " 'lehrer-geßner-straße',\n",
              " 'wittekindallee',\n",
              " 'am darloh',\n",
              " 'taxusweg',\n",
              " 'hinterm friedhof',\n",
              " 'kleine wende',\n",
              " 'an der liff',\n",
              " 'posthorn',\n",
              " 'landsberger allee']"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ],
      "source": [
        "streetnames[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "yRzVx_hBqr7_"
      },
      "outputs": [],
      "source": [
        "# Create training, dev, and test sets\n",
        "train_index = floor(len(streetnames) * 0.90)\n",
        "dev_index = floor(len(streetnames) * 0.95)\n",
        "\n",
        "train = streetnames[:train_index]\n",
        "dev = streetnames[train_index:dev_index]\n",
        "test = streetnames[dev_index:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_token = '.'"
      ],
      "metadata": {
        "id": "GJq5MXh02Az4"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "MSYXOJdDl_WC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join([special_token] + streetnames))))\n",
        "\n",
        "# Create look up tables for the alphabet\n",
        "  # stoi = string to index\n",
        "  # itos = index to string\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for s, i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itos.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho2wAPG21H_o",
        "outputId": "94e61c71-6b79-4da3-b8b8-2fb94f7564fc"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([' ', '&', \"'\", '-', '.', ':', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ß', 'ä', 'ö', 'ü'])"
            ]
          },
          "metadata": {},
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yn3roeTqr8A",
        "outputId": "338bfd98-ccf7-40f0-fe5a-a907528587db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ],
      "source": [
        "alphabet_size = len(chars)\n",
        "alphabet_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "Nvmdz3M6luLH",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c479f233-2e6b-4749-8056-2af5a70d3c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples:  2753260\n"
          ]
        }
      ],
      "source": [
        "xs_train,  ys_train = [], []\n",
        "\n",
        "# Create the training data\n",
        "# input xs: (ch1, ch2) \n",
        "# prediction ys: ch3\n",
        "for streetname in train:\n",
        "\n",
        "  # prepend two special characters and append one special characters to each streetname\n",
        "  chs = [special_token] * 2 + list(streetname) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_train.append((ix1, ix2))\n",
        "    ys_train.append(ix3)\n",
        "\n",
        "num = len(xs_train)\n",
        "print('number of training examples: ', num)\n",
        "xs_train = torch.tensor(xs_train, device=device)\n",
        "ys_train = torch.tensor(ys_train, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH8z6Bs0qr8B",
        "outputId": "b3abf563-e608-4d44-c386-078d36825c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of development examples:  306006\n"
          ]
        }
      ],
      "source": [
        "# Create the dev data\n",
        "xs_dev,  ys_dev = [], []\n",
        "for word in dev:\n",
        "  chs = [special_token] * 2 + list(word) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_dev.append((ix1, ix2))\n",
        "    ys_dev.append(ix3)\n",
        "\n",
        "xs_dev = torch.tensor(xs_dev, device=device)\n",
        "ys_dev = torch.tensor(ys_dev, device=device)\n",
        "print('number of development examples: ', xs_dev.nelement())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1y0NbDZqr8C",
        "outputId": "bf461f38-3c01-442b-92cc-a69da06437fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of testing examples:  304704\n"
          ]
        }
      ],
      "source": [
        "# Create the test data\n",
        "xs_test,  ys_test = [], []\n",
        "for word in test:\n",
        "  chs = [special_token] * 2 + list(word) + [special_token]\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs_test.append((ix1, ix2))\n",
        "    ys_test.append(ix3)\n",
        "\n",
        "xs_test = torch.tensor(xs_test, device=device)\n",
        "ys_test = torch.tensor(ys_test, device=device)\n",
        "print('number of testing examples: ', xs_test.nelement())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "7ZQ_3pnsqr8C"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator(device=device).manual_seed(2147483647)\n",
        "W = torch.randn((alphabet_size*2, alphabet_size), generator=g, device=device, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw78JHSfqr8D",
        "outputId": "e41fb01d-df0d-4032-e290-0fe543f33434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at step 0: 4.512\n",
            "loss at step 50: 2.205\n",
            "loss at step 100: 2.111\n",
            "loss at step 150: 2.080\n",
            "loss at step 200: 2.061\n",
            "loss at step 250: 2.059\n",
            "loss at step 300: 2.059\n",
            "loss at step 350: 2.058\n",
            "loss at step 400: 2.058\n",
            "loss at step 450: 2.058\n",
            "final training loss: 2.057, with smoothing strength 0.01\n"
          ]
        }
      ],
      "source": [
        "# gradient descent\n",
        "iterations = 500\n",
        "learning_rate = 200\n",
        "smoothing_strenth = 0.01\n",
        "\n",
        "for k in range(iterations):\n",
        "\n",
        "  # forward pass\n",
        "  xenc= F.one_hot(xs_train, num_classes=alphabet_size).float()\n",
        "  xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "  logits = xenc_flat @ W # predict log-counts\n",
        "  loss = F.cross_entropy(logits, ys_train) + smoothing_strenth * (W**2).mean() # compute loss\n",
        "  # print loss every 10% of iterations\n",
        "  if k % floor(iterations/10) == 0:\n",
        "    print(f'loss at step {k}: {loss.item():.3f}')\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # flush the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # update step\n",
        "  cool_down = 1.0 / (1 + 0.01 * k)\n",
        "  W.data += -learning_rate * cool_down * W.grad\n",
        "print(f'final training loss: {loss.item():.3f}, with smoothing strength {smoothing_strenth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sJQXZYBqr8D",
        "outputId": "7dedd516-a8a9-4a55-b159-93bc0a97caf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss on dev set: 2.040, with smoothing strength 0.01\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the dev set\n",
        "xenc= F.one_hot(xs_dev, num_classes=alphabet_size).float()\n",
        "xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "logits = xenc_flat @ W # predict log-counts\n",
        "# softmax\n",
        "counts = logits.exp() # counts\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# loss function (cross-entropy) + regularization (L2)\n",
        "loss = F.cross_entropy(logits, ys_dev)\n",
        "print(f'loss on dev set: {loss.item():.3f}, with smoothing strength {smoothing_strenth}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqlMBsbXqr8D",
        "outputId": "a237ebd5-f28d-4974-a803-6e29235f694d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss on test set: 2.061\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "xenc= F.one_hot(xs_test, num_classes=alphabet_size).float()\n",
        "xenc_flat = xenc.flatten(1) # flatten the one-hot encoded input vector\n",
        "logits = xenc_flat @ W # predict log-counts\n",
        "# softmax\n",
        "counts = logits.exp() # counts\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# loss function (cross-entropy) + regularization (L2)\n",
        "loss = F.cross_entropy(logits, ys_test) + smoothing_strenth * (W**2).mean() # compute loss\n",
        "print(f'loss on test set: {loss.item():.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0mkbei4qr8E",
        "outputId": "8a0049ea-bf80-473d-893e-719cc4edb086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ga-strkoreindjjake.\n",
            "hanwol-hen de.\n",
            "arastraße.\n",
            "aner straße.\n",
            "bag-z.\n",
            "vilbaufsuren.\n",
            "imobner wies-old.\n",
            "ser.\n",
            "benborde.\n",
            "sendenätsper weg.\n",
            "rindet.\n",
            "fendiuxweg.\n",
            "jecken dwes ald-rtgerwereg.\n",
            "weg.\n",
            "obeildts-steimbre-ge.\n",
            "aurweg.\n",
            "mmieg.\n",
            "arnachaul-weg.\n",
            "of.\n",
            "haustraße.\n",
            "haundeit.\n",
            "llter dühl-gauf.\n",
            "borpistr der wegern-weg.\n",
            "andstraßerweiläusstod.\n",
            "chkim gerbstenm weg.\n",
            "batzen.\n",
            "heraße.\n",
            "mofkertweg.\n",
            "böstraße.\n",
            "winsthng.\n",
            "rnhupwegereh.\n",
            "taastraße.\n",
            "haubler stichtraße.\n",
            "jastraße.\n",
            "am chhraße.\n",
            "jalbreomafl-elee denhen.\n",
            "kaystatraße.\n",
            "tben sjog.\n",
            "rochaulestraße.\n",
            "kuberger straße.\n",
            "düstrastr atz-plaraße.\n",
            "amer örmest.\n",
            "votbachuf.\n",
            "rum kttandericker bahofse.\n",
            "fer wilsten.\n",
            "psteelen.\n",
            "lereße.\n",
            "pastraße.\n",
            "bucherstraße.\n",
            "ornsilberg.\n",
            "kot.\n",
            "waber.\n",
            "ülstraße.\n",
            "traße.\n",
            "mühkale.\n",
            "kingalerg.\n",
            "alttam .\n",
            "karie-dotziegersweg.\n",
            "wzwel.\n",
            "raße.\n",
            "dor'inb-jokarp.\n",
            "zulgen dem ges ronder dtben dphieg.\n",
            "jofferiestrathraße.\n",
            "areße.\n",
            "zuach.\n",
            "peten weg.\n",
            "schef derwegrausg.\n",
            "intstrep.\n",
            "zem raße.\n",
            "ackserweg straße.\n",
            "raße.\n",
            "ben dhallttwar pllicken derstraße.\n",
            "um gaberberheveng.\n",
            "spökelder ufelweld.\n",
            "uerl-hol-svuichemartropstraster-straße.\n",
            "öhelbeim rteofrragraun heinan straße.\n",
            "aloble.\n",
            "brottten.\n",
            "am vergenstraße.\n",
            "wegrüblerg.\n",
            "kaplangelen descheppashützer.\n",
            "andser herbergullseilhinacke.\n",
            "var ße.\n",
            "sam weg.\n",
            "laaldweitz.\n",
            "inzuychern-hoffstraße.\n",
            "rühlahlitraße.\n",
            "eflsweg.\n",
            "lothalzueferwek.\n",
            "horkrm taastraße.\n",
            "llansgelrestraße.\n",
            "mer wehwittammer-bach.\n",
            "tiamerstrentraßel.\n",
            "weg.\n",
            "am luraßerstraße.\n",
            "mausgaültrte.\n",
            "gädstraße.\n",
            "ale.\n",
            "oick-mandsarder welbersweim einhor straße.\n",
            "am keserield.\n"
          ]
        }
      ],
      "source": [
        "g = torch.Generator(device=device).manual_seed(2147483647)\n",
        "# sample street names\n",
        "name_count = 100\n",
        "sampled_street_names = []\n",
        "for i in range(name_count):\n",
        "\n",
        "  out = []\n",
        "  ix1 = stoi[special_token]\n",
        "  ix2 = stoi[special_token]\n",
        "\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2], device=device), num_classes=alphabet_size).float()\n",
        "    xenc_flat = xenc.flatten()\n",
        "    logits = xenc_flat @ W # predict log-counts\n",
        "    # softmax\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(0, keepdims=True) # probabilities for next character\n",
        "    \n",
        "    # move index to next character\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == stoi[special_token]:\n",
        "      # stop if we reach the end of the word\n",
        "      # 0 is the index of the special character '.'\n",
        "      break\n",
        "\n",
        "  sampled_street_names.append(''.join(out))\n",
        "for streetname in sampled_street_names:\n",
        "  print(streetname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = ['a', 'm']\n",
        "ix1 = stoi[out[0]]\n",
        "ix2 = stoi[out[1]]\n",
        "\n",
        "while True:\n",
        "  xenc = F.one_hot(torch.tensor([ix1, ix2], device=device), num_classes=alphabet_size).float()\n",
        "  xenc_flat = xenc.flatten()\n",
        "  logits = xenc_flat @ W # predict log-counts\n",
        "  # softmax\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  p = counts / counts.sum(0, keepdims=True) # probabilities for next character\n",
        "  \n",
        "  # move index to next character\n",
        "  ix1 = ix2\n",
        "  ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "  out.append(itos[ix2])\n",
        "  if ix2 == stoi[special_token]:\n",
        "    # stop if we reach the end of the word\n",
        "    # 0 is the index of the special character '.'\n",
        "    break\n",
        "print(''.join(out))"
      ],
      "metadata": {
        "id": "kL-GtDgODDVj",
        "outputId": "131ec711-a9c0-4e7f-d051-49aa61b3cfab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "am raße.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}