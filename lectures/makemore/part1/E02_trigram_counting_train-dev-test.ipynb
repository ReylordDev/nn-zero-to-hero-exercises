{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "smXrGT8fkBXb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the names\n",
    "words = open('../names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7Sr6q5tolfnr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the counts tensor\n",
    "N = torch.zeros(27, 27, 27, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "MSYXOJdDl_WC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(['.'] + words))))\n",
    "\n",
    "# Create look up tables for the alphabet\n",
    "  # stoi = string to index\n",
    "  # itos = index to string\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Nvmdz3M6luLH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "\n",
    "# Create the training data\n",
    "for word in words:\n",
    "\n",
    "  # prepend two special characters and append one special characters to each word\n",
    "  chs = ['.'] * 2 + list(word) + ['.']\n",
    "  # Example for 'anna\": \n",
    "  # zip(chs, chs[1:], chs[2:]) = \n",
    "  # [('.', '.', 'a'), ('.', 'a', 'n'), ('a', 'n', 'n'), ('n', 'n', 'a'), ('n', 'a', '.')]\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    N[ix1, ix2, ix3] += 1\n",
    "    num += 1\n",
    "\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_-e3yfdCr_wc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the counts to get probabilities\n",
    "P = (N+1).float()\n",
    "P /= P.sum(2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJGEnJmbyO8D",
    "outputId": "36f1b9c1-375d-469e-b0ac-00ebdc3086c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miq.', 'axx.', 'mereyannyaar.', 'knooraen.', 'el.', 'marviovania.', 'odarimalabelon.', 'hamirelslen.', 'elyn.', 'rae.', 'bra.', 'ceevlainacelonikaireil.', 'bech.', 'amilleia.', 'trutandennimsaby.', 'crewina.', 'lanoxvkyrina.', 'khine.', 'trise.', 'koberseberryslot.']\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# sample names\n",
    "name_count = 20\n",
    "sampled_words = []\n",
    "for i in range(name_count):\n",
    "\n",
    "  out = []\n",
    "  ix1 = 0\n",
    "  ix2 = 0\n",
    "\n",
    "  while True:\n",
    "    p = P[ix1, ix2]\n",
    "    # move index to next character\n",
    "    ix1 = ix2\n",
    "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix2])\n",
    "    if ix2 == 0:\n",
    "      # stop if we reach the end of the word\n",
    "      # 0 is the index of the special character '.'\n",
    "      break\n",
    "\n",
    "  sampled_words.append(''.join(out))\n",
    "print(sampled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWqRBcat7Iml",
    "outputId": "a4b061d6-8082-4aa9-d0ab-393e8f2da759",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll=504653.00\n",
      "2.21\n"
     ]
    }
   ],
   "source": [
    "# Compute the negative log likelihood of the data\n",
    "\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for word in words:\n",
    "  chs = ['.'] * 2 + list(word) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    prob = P[ix1, ix2, ix3]\n",
    "    log_likelihood += torch.log(prob)\n",
    "    n += 1\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=:.2f}')\n",
    "print(f'{nll/n:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of trigram counts\n",
    "\n",
    "average loss: 2.21\n",
    "\n",
    "Improvement compared to bigram model: 2.45-2.21 = 0.24\n",
    "Improvement compared to trigram nn model: 2.40-2.21 = 0.19"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
